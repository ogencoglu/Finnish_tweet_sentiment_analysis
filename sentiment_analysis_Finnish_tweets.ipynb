{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick and dirty sentiment analysis of tweets by Finnish political party leaders (as of November 2021)\n",
    "Author: [Oguzhan (Ouz) Gencoglu](https://www.linkedin.com/posts/ogencoglu_nlp-activity-6861189201119989760-P2-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "from collections import Counter\n",
    "from itertools import compress\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the data\n",
    "\n",
    "First run *twint* from command line for each Twitter user, e.g.: \n",
    ">twint -u marinsanna --timeline -o marinsanna.csv --csv\n",
    "\n",
    "Save the csv files under *'data/'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    'turtiainenano': 'Ano Turtiainen',\n",
    "    'mariaohisalo': 'Maria Ohisalo',\n",
    "    'annikasaarikko': 'Annika Saarikko',\n",
    "    'sariessayah': 'Sari Essayah',\n",
    "    'petteriorpo': 'Petteri Orpo',\n",
    "    'anna_maja': 'Anna-Maja Henriksson',\n",
    "    'hjallisharkimo': 'Harry Harkimo',\n",
    "    'liandersson': 'Li Andersson',\n",
    "    'ir_rkp': 'Riikka Purra',\n",
    "    'marinsanna': 'Sanna Marin',\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all data into a dataframe\n",
    "filepaths = glob(pathname=\"data/*.csv\")\n",
    "top = 500\n",
    "data = []\n",
    "for p in filepaths:\n",
    "    temp = pd.read_csv(p, delimiter=\"\\t\", usecols=[\"username\", \"retweet_id\", \"tweet\"])\n",
    "    temp = temp[temp[\"retweet_id\"].isna()][0:top]  # filter out retweets\n",
    "    data.append(temp)\n",
    "data = pd.concat(data)\n",
    "data.drop([\"retweet_id\"], inplace=True, axis=1)\n",
    "data[\"username\"] = data[\"username\"].map(name_map)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pprint(Counter(data[\"username\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained Finnish sentiment classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"fergusq/finbert-finnsentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"fergusq/finbert-finnsentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify sentiment of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tokenizer, model, batch_of_text):\n",
    "    batch = tokenizer(batch_of_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    outputs = model(**batch)\n",
    "    predictions = nn.functional.softmax(outputs.logits, dim=-1)  # this is important!\n",
    "    return predictions.cpu().detach().numpy()\n",
    "\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "batches = chunks(lst=list(data[\"tweet\"]), n=50)\n",
    "preds = []  # neg | neut | pos\n",
    "for batch in tqdm(batches):\n",
    "    pred = get_sentiment(tokenizer=tokenizer, model=model, batch_of_text=batch)\n",
    "    preds.append(pred)\n",
    "preds = np.vstack(preds)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the labels to dataframe\n",
    "data[\"neg\"] = preds[:, 0]\n",
    "data[\"neut\"] = preds[:, 1]\n",
    "data[\"pos\"] = preds[:, 2]\n",
    "data[\"class\"] = data[[\"neg\", \"neut\", \"pos\"]].idxmax(axis=1)\n",
    "\n",
    "# groupby\n",
    "counts = data.groupby([\"username\", \"class\"]).count().reset_index()\n",
    "counts[\"tweet\"] = counts[\"tweet\"]/5  # turn into %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "g = sns.catplot(data=counts, kind=\"bar\", x=\"class\", y=\"tweet\", hue=\"username\",\n",
    "    ci=None, palette=\"tab10\", alpha=.8, height=9, aspect=1.4, legend_out=False)\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"% of last 500 tweets\")\n",
    "g.legend.set_title(\"\")\n",
    "g.set_yticklabels(size=15)\n",
    "plt.legend(fontsize='x-large', title_fontsize='40')\n",
    "plt.show()\n",
    "\n",
    "g.fig.savefig('plot.png', dpi=600, bbox_inches='tight')  # save image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
